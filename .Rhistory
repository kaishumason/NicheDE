materials_all[[counter]] = CreateNicheDEObject(counts_mat = counts,coord,L,deconv_true,c(1),counts = T)
#update counter
counter = counter +1
}
NDE = MergeObjects(materials_all)
NDE = CalculateEffectiveNiche(NDE)
rm(list=ls()[! ls() %in% c("NDE")])
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs.txt")
end_time = Sys.time()
print(end_time-start_time)
gc()
memory.linit()
memory.limit()
library(usethis)
usethis::edit_r_environ()
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
library(RCTD)
library(Matrix)
library(Seurat)
library(ggplot2)
library(patchwork)
library(abind)
library(enrichR)
#library(nicheDE)
#THIS is the one i'm using for NGA
nb_lik = function(x,mu,disp){
#returns negative log likelihood: Var = mu + mu^2/size
return(-sum(dnbinom(x=x, size = disp, mu = mu,log = TRUE)))
}
source("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Anuja\\niche_gene_functions_github.R")
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\new_reference")
#L = read.table(file = "Library_reference.txt", sep = " ")
L = readRDS('L_merge.rds')
colnames(L) = toupper(colnames(L))
L = as.matrix(L)
kernel_materials = vector(mode = 'list',length = 3)
counter_rank = 1
direcs = c("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver1",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver2",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver4",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Crc_Visium_deeper_sequencing\\22261_visium",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Crc_Visium_deeper_sequencing\\22996_visium\\outs")
tum_hep_ind = c(1,4)
counter = 1
materials_all = vector(mode = 'list',length = length(direcs))
for(sample in direcs){
sobj = Load10X_Spatial(sample, filename="filtered_feature_bc_matrix.h5")
#Make object
counts = sobj@assays$Spatial@counts
dim(counts)
counts = apply(counts,1,function(x){pmin(x,quantile(x,0.995))})
counts = floor(counts)
#counts = t(counts)
coord = sobj@images[["slice1"]]@coordinates[,4:5]
setwd(sample)
deconv_true = readRDS(paste0(sample,'\\deconv_merge.rds'))
deconv_true = as.matrix(deconv_true)
deconv_true[,tum_hep_ind[1]] = deconv_true[,tum_hep_ind[1]]*(deconv_true[,tum_hep_ind[1]]>0.25)
deconv_true[,tum_hep_ind[2]] = deconv_true[,tum_hep_ind[2]]*(deconv_true[,tum_hep_ind[2]]>0.25)
materials_all[[counter]] = CreateNicheDEObject(counts_mat = counts,coord,L,deconv_true,c(1,100,250),counts = T)
#update counter
counter = counter +1
}
NDE = MergeObjects(materials_all)
NDE = CalculateEffectiveNiche(NDE)
rm(list=ls()[! ls() %in% c("NDE")])
gc()
object.size(NDE)
object.size(NDE)/1000000000
counter = 1
i = 1
object.size(object@ref_expr[,i])/1000000000
object.size(NDE@ref_expr[,i])/1000000000
object.size(NDE@ref_expr[,i])/1000000
object.size(NDE@effective_niche[[counter]])/1000000
object.size(NDE@num_cells,object@null_expected_expression[,i])/1000000
object.size(NDE@null_expected_expression[,i])/1000000
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5.txt")
end_time = Sys.time()
print(end_time-start_time)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5.txt")
end_time = Sys.time()
print(end_time-start_time)
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE_par = niche_DE_parallel(NDE,C = 150, M = 10, gamma = 0.8,cores = 4,Int = T,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs.txt")
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
devtools::install_github("Kmason23/NicheDE") # install
detach("package:nicheDE", unload=TRUE)
devtools::install_github("Kmason23/NicheDE") # install
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5.txt")
end_time = Sys.time()
print(end_time-start_time)
library(nicheDE)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5.txt")
end_time = Sys.time()
print(end_time-start_time)
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
library(RCTD)
library(Matrix)
library(Seurat)
library(ggplot2)
library(patchwork)
library(abind)
library(enrichR)
#library(nicheDE)
#THIS is the one i'm using for NGA
nb_lik = function(x,mu,disp){
#returns negative log likelihood: Var = mu + mu^2/size
return(-sum(dnbinom(x=x, size = disp, mu = mu,log = TRUE)))
}
source("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Anuja\\niche_gene_functions_github.R")
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\new_reference")
#L = read.table(file = "Library_reference.txt", sep = " ")
L = readRDS('L_merge.rds')
colnames(L) = toupper(colnames(L))
L = as.matrix(L)
kernel_materials = vector(mode = 'list',length = 3)
counter_rank = 1
direcs = c("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver1",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver2",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\CancerDiscovery_mCRC_Visium_scRNA\\ST\\ST-liver4",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Crc_Visium_deeper_sequencing\\22261_visium",
"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\Crc_Visium_deeper_sequencing\\22996_visium\\outs")
tum_hep_ind = c(1,4)
counter = 1
materials_all = vector(mode = 'list',length = length(direcs))
for(sample in direcs){
sobj = Load10X_Spatial(sample, filename="filtered_feature_bc_matrix.h5")
#Make object
counts = sobj@assays$Spatial@counts
dim(counts)
counts = apply(counts,1,function(x){pmin(x,quantile(x,0.995))})
counts = floor(counts)
#counts = t(counts)
coord = sobj@images[["slice1"]]@coordinates[,4:5]
setwd(sample)
deconv_true = readRDS(paste0(sample,'\\deconv_merge.rds'))
deconv_true = as.matrix(deconv_true)
deconv_true[,tum_hep_ind[1]] = deconv_true[,tum_hep_ind[1]]*(deconv_true[,tum_hep_ind[1]]>0.25)
deconv_true[,tum_hep_ind[2]] = deconv_true[,tum_hep_ind[2]]*(deconv_true[,tum_hep_ind[2]]>0.25)
materials_all[[counter]] = CreateNicheDEObject(counts_mat = counts,coord,L,deconv_true,c(1,100,250),counts = T)
#update counter
counter = counter +1
}
NDE = MergeObjects(materials_all)
NDE = CalculateEffectiveNiche(NDE)
library(RCTD)
library(Matrix)
library(Seurat)
library(ggplot2)
library(patchwork)
library(abind)
library(enrichR)
#library(nicheDE)
saveRDS(NDE,"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NDE.rds")
#NDE = readRDS("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NDE.rds")
rm(list=ls()[! ls() %in% c("NDE","nicheDE")])
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 8,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
#saveRDS(NDE,"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NDE.rds")
object.size(NDE@effective_niche[[2]])
object.size(NDE@effective_niche[[3]])
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
library(pryr)
install.packages("pryr")
library(pryr)
find_biggest(5)
pryr::find_biggest(2)
mem_used
mem_used()
mem_available()
# Get the memory used by R in megabytes
memory_used <- utils::memory.size()
# Get the maximum memory available to R in megabytes
memory_limit <- memory.limit()
# Calculate the memory left
memory_left <- memory_limit - memory_used
# Print the results
cat("Memory used by R:", memory_used, "MB\n")
cat("Memory limit in R:", memory_limit, "MB\n")
cat("Memory left in R:", memory_left, "MB\n")
memory.size(max = TRUE)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
gc()
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
doParallel::stopImplicitCluster()
cl <- parallel::makeCluster(cores,outfile = outfile)
doParallel::registerDoParallel(cl)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
doParallel::stopImplicitCluster()
cl <- parallel::makeCluster(cores,outfile = outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs11.txt")
doParallel::registerDoParallel(cl)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
rm(list=ls()[! ls() %in% c("NDE","nicheDE")])
gc()
cl <- parallel::makeCluster(cores,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs11.txt")
doParallel::registerDoParallel(cl)
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs11.txt")
doParallel::registerDoParallel(cl)
start_time = Sys.time()
NDE = niche_DE_parallel(NDE,C = 400,M = 10,gamma = 0.8,cores = 4,
outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs10.txt")
end_time = Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
doparallel::detect_cores()
foreach::detect_cores()
?detect_cores()
#library(nicheDE)
saveRDS(NDE,"C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NDE.rds")
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs11.txt")
View(NDE)
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
detach("nicheDE")
detach("package::nicheDE")
detach("package:nicheDE", unload=TRUE)
devtools::install_github("Kmason23/NicheDE") # install
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
detach("package:nicheDE", unload=TRUE)
devtools::install_github("Kmason23/NicheDE") # install
library(CellTrek)
library(ggplot2)
library(nicheDE)
library(Seurat)
library(varhandle)
#load cell trek data for HK2770
celltrek = readRDS("C:\\Users\\Kaishu\\Dropbox (Penn)\\Amin_Data\\HK_2871\\HK2871.All.HK.SC_celltrek.New.4.11.2023.rds")
celltrek@meta.data$orig.ident = gsub("\\_","",celltrek@meta.data$orig.ident)
#plot celltrek results
Idents(celltrek) = celltrek@meta.data$Idents
SpatialDimPlot(celltrek)
###### Niche-DE on celltrek single cell resolution data
setwd("C:\\Users\\Kaishu\\Desktop\\Amin_ST")
#Read in reference
refr = readRDS("idents\\HK.SC.NewIdents.Order.3.23.rds")
#get raw counts
#count_raw <- refr@assays$RNA@data
#colnames(count_raw) = refr@assays$RNA@data@Dimnames[[2]]
#Read in single cell mean library
refr@assays$RNA@counts = refr@assays$RNA@data
L = CreateLibraryMatrixFromSeurat(refr,"RNA")
#get counts matrix from single cells
#cell_match = match(celltrek@assays$RNA@data@Dimnames[[2]],refr@assays$RNA@data@Dimnames[[2]])
#cell_match = cell_match[is.na(cell_match)==F]
#count_raw = count_raw[,cell_match]
#remove refr
count_raw = celltrek@assays$RNA@data
rm("refr")
#make deconvolution matrix
nspot = ncol(count_raw)
nCT = nrow(L)
deconv_mat = matrix(0,nspot,nCT)
#rename rows and columns
colnames(deconv_mat) = rownames(L)
rownames(deconv_mat) = colnames(count_raw)
#get cell tyeps
CT = rownames(L)
#update deconv mat
#change names in ideents
ID = unfactor(celltrek@meta.data$Idents)
ID[ID=="Fibroblast"] = "Fibroblast_2"
ID[ID=="DCT/CNT/PC"] = "DCT"
ID[ID=="iPT"] = "Injured_PT"
ID[ID=="B_Cells"] = "B_Naiive"
ID[ID=="Podo/Mes"] = "Podo"
ID[ID=="Prolif"] = "PC"
ID[ID=="Mono"] = "CD14_Mono"
ID[ID=="DC"] = "pDC"
for(j in c(1:nrow(deconv_mat))){
cell_type = ID[j]
#get which column of deconv should be updated
ind = which(CT == cell_type)
#update column of deconv_mat
deconv_mat[j,ind] = 1
}
#get coordinates
coord_mat = GetTissueCoordinates(celltrek)
####Remove rare CT
top_CT = names(sort(table(ID),decreasing = T)[1:15])
mean(ID%in%top_CT)
L = L[top_CT,]
rare_cells = which(ID%in%top_CT == F)
deconv_mat = deconv_mat[-rare_cells,top_CT]
count_raw = count_raw[,-rare_cells]
coord_mat = coord_mat[-rare_cells,]
#transpose data
counts_mat = t(as.matrix(count_raw))
#make niche-DE object
NDE = CreateNicheDEObject(counts_mat,coord_mat,L,deconv_mat,sigma = c(100,200,300),counts = F)
rm(list=setdiff(ls(), "NDE"))
#calculate Effective niche
NDE = CalculateEffectiveNiche(NDE)
gc()
colSums(NDE@counts)
summary(colSums(NDE@counts))
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs50.txt")
doParallel::registerDoParallel(cl)
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 50,gamma = 0.8,cores = 2,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs50.txt")
doParallel::registerDoParallel(cl)
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 50,gamma = 0.8,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
dim(NDE@counts)
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs500.txt")
doParallel::registerDoParallel(cl)
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 20,gamma = 0.8,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
doParallel::stopImplicitCluster()
# library(devtools)
# install_github("navinlabcode/CellTrek")
#devtools::install_github("Kmason23/NicheDE") # install
library(CellTrek)
library(ggplot2)
library(nicheDE)
library(Seurat)
library(varhandle)
#load cell trek data for HK2770
celltrek = readRDS("C:\\Users\\Kaishu\\Dropbox (Penn)\\Amin_Data\\HK_2871\\HK2871.All.HK.SC_celltrek.New.4.11.2023.rds")
celltrek@meta.data$orig.ident = gsub("\\_","",celltrek@meta.data$orig.ident)
#plot celltrek results
Idents(celltrek) = celltrek@meta.data$Idents
SpatialDimPlot(celltrek)
###### Niche-DE on celltrek single cell resolution data
setwd("C:\\Users\\Kaishu\\Desktop\\Amin_ST")
#Read in reference
refr = readRDS("idents\\HK.SC.NewIdents.Order.3.23.rds")
#get raw counts
#count_raw <- refr@assays$RNA@data
#colnames(count_raw) = refr@assays$RNA@data@Dimnames[[2]]
#Read in single cell mean library
refr@assays$RNA@counts = refr@assays$RNA@data
L = CreateLibraryMatrixFromSeurat(refr,"RNA")
#get counts matrix from single cells
#cell_match = match(celltrek@assays$RNA@data@Dimnames[[2]],refr@assays$RNA@data@Dimnames[[2]])
#cell_match = cell_match[is.na(cell_match)==F]
#count_raw = count_raw[,cell_match]
#remove refr
count_raw = celltrek@assays$RNA@data
rm("refr")
#make deconvolution matrix
nspot = ncol(count_raw)
nCT = nrow(L)
deconv_mat = matrix(0,nspot,nCT)
#rename rows and columns
colnames(deconv_mat) = rownames(L)
rownames(deconv_mat) = colnames(count_raw)
#get cell tyeps
CT = rownames(L)
#update deconv mat
#change names in ideents
ID = unfactor(celltrek@meta.data$Idents)
ID[ID=="Fibroblast"] = "Fibroblast_2"
ID[ID=="DCT/CNT/PC"] = "DCT"
ID[ID=="iPT"] = "Injured_PT"
ID[ID=="B_Cells"] = "B_Naiive"
ID[ID=="Podo/Mes"] = "Podo"
ID[ID=="Prolif"] = "PC"
ID[ID=="Mono"] = "CD14_Mono"
ID[ID=="DC"] = "pDC"
for(j in c(1:nrow(deconv_mat))){
cell_type = ID[j]
#get which column of deconv should be updated
ind = which(CT == cell_type)
#update column of deconv_mat
deconv_mat[j,ind] = 1
}
#get coordinates
coord_mat = GetTissueCoordinates(celltrek)
####Remove rare CT
top_CT = names(sort(table(ID),decreasing = T)[1:15])
mean(ID%in%top_CT)
L = L[top_CT,]
rare_cells = which(ID%in%top_CT == F)
deconv_mat = deconv_mat[-rare_cells,top_CT]
count_raw = count_raw[,-rare_cells]
coord_mat = coord_mat[-rare_cells,]
#transpose data
counts_mat = t(as.matrix(count_raw))
# #subset data
# subset = which(coord_mat[,1]<150 & coord_mat[,2]>400)
# counts_mat_subset = counts_mat[subset,]
# deconv_mat_subset = deconv_mat[subset,]
# coord_mat_subset = coord_mat[subset,]
#make niche-DE object
NDE = CreateNicheDEObject(counts_mat,coord_mat,L,deconv_mat,sigma = c(100,200,300),counts = F)
rm(list=setdiff(ls(), "NDE"))
#calculate Effective niche
NDE = CalculateEffectiveNiche(NDE)
gc()
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5000.txt")
doParallel::registerDoParallel(cl)
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 20,gamma = 0.8,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
gc()
pryr::mem_used()
gc()
# Get a list of objects in the current environment
objects <- ls()
# Calculate the sizes of each object
object_sizes <- sapply(objects, function(obj) object_size(get(obj)))
# Combine the object names and sizes into a data frame
object_sizes_df <- data.frame(Object = names(object_sizes), Size = object_sizes)
# Print the list of objects and their sizes
print(object_sizes_df)
pryr::mem_used()
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 20,gamma = 0.8,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
cl <- parallel::makeCluster(4,outfile = "C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\logs5000.txt")
doParallel::registerDoParallel(cl)
#run niche-DE
#start time of funtion
start_time <- Sys.time()
#run niche-DE
NDE = niche_DE_parallel(NDE,C =400,M = 20,gamma = 0.8,print = T,Int = F)
#end time of function
end_time <- Sys.time()
print(end_time-start_time)
doParallel::stopImplicitCluster()
setwd("C:\\Users\\Kaishu\\Dropbox (Penn)\\Visium\\niche_DE_package\\NicheDE_github")
devtools::document()
